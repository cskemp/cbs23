{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "732c1c1e997d3b8e3384864eb0e343f6",
     "grade": false,
     "grade_id": "cell-4886e12e4cb1522c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CBS Week 8 Assessment: Bayesian Concept Learning\n",
    "## Semester 2 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4691226a9553ba1071a5561d9375e33",
     "grade": false,
     "grade_id": "cell-0ef323c7a8a43bb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "    library(testthat)\n",
    "    library(knitr)\n",
    "    library(kableExtra)\n",
    "    library(IRdisplay)  \n",
    "})\n",
    "\n",
    "options(repr.plot.width=16, repr.plot.height=8)\n",
    "\n",
    "# a function for displaying tables\n",
    "show_table <- function(d) {\n",
    "    kable(d, \"html\", align=\"c\")  %>% \n",
    "        as.character()  %>% \n",
    "        display_html()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70c276e21aa1a0953dc77064479ad2a1",
     "grade": false,
     "grade_id": "cell-f28a15cad4ff6578",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This notebook is due on September 22. Please make sure that your notebook validates before you submit it --- if your notebook doesn't validate the automated grader may run into issues.\n",
    "\n",
    "This notebook will explore a simple version of Josh Tenenbaum's number game. The number game was covered in class this week, and is also described by the Murphy reading available on Canvas. In class we discussed a version of the number game that considered integers between 1 and 100. Here we'll make things even simpler and will consider only integers between 1 and 12.\n",
    "\n",
    "\n",
    "The number game involves inferences about a concept $C$. For example, if $C$ is the concept \"even numbers\", the extension of $C$ would be $\\{2,4,6,8,10,12\\}$. If $C$ is the concept \"numbers between 4 and 6\", then the extension would be $\\{4,5,6\\}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a18e30106c04d4a00aa8ceef03f3f42",
     "grade": false,
     "grade_id": "cell-76d688a46742c703",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 1 (1 point)\n",
    "\n",
    "Given that we are working with integers from 1 to 12 (inclusive), how many different extensions of concept $C$ are possible? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efbe30911f17e3117915012eaa5fe968",
     "grade": true,
     "grade_id": "cell-867748d870542027",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57d5e863ac348f35949318a78db75d79",
     "grade": false,
     "grade_id": "cell-4b7f3cdc7b25b207",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hypothesis space $\\mathcal{H}$ and priors $p(h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67914ff19c08c93a614faa2c9354be76",
     "grade": false,
     "grade_id": "cell-94c04b6dc6710b52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As for last week's tutorial notebook, we'll use a tabular approach to Bayesian inference. We'll construct a data frame where each row corresponds to a hypothesis about the extension of concept $C$, and where priors and likelihood functions are stored in columns. We're going to consider four different priors and two different likelihood functions (strong and weak sampling). Combining these priors and likelihood functions produces a total of 8 different Bayesian models.\n",
    "\n",
    "Let's start by setting up the hypothesis space $\\mathcal{H}$ and the priors. Provided that you understand how the priors are defined, the code for setting up these priors is not that important for our purposes, so feel free to skim it.\n",
    "\n",
    "First we define two helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96f40a957bbc3683d2b68bf744dee7c6",
     "grade": false,
     "grade_id": "cell-8e7ac847579a8e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# A helper function that sets bits in H_VEC (a 12 element vector) corresponding to H_MEMBERS, a set of \n",
    "# concept members \n",
    "\n",
    "set_member_indices <- function(h_vec, h_members) {\n",
    "  h_vec[h_members] <- 1\n",
    "  return(h_vec)\n",
    "}\n",
    "\n",
    "# ... and a helper function that converts a H_VEC to a string\n",
    "indices_to_str<- function(h_vec) {\n",
    "  paste0(which(h_vec==1), collapse=\"/\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d909665c5c1bd7e2d7bba675fe7227da",
     "grade": false,
     "grade_id": "cell-820d9b0642709b40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now define `h_math`, a hypothesis space including 8 mathematical concepts and a uniform prior (`prior_math`) over this hypothesis space. Eight mathematical concepts will be enough for our purposes but others could be included (e.g. \"powers of 2\", or \"cube numbers\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10afcdcd684c9f75f1d21539b4dbbecc",
     "grade": false,
     "grade_id": "cell-4b95ba96c55b7d4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n <- 12\n",
    "zeros <- replicate(n, 0)\n",
    "h_math <-\n",
    "  tibble(h_members = list(\n",
    "    c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),   # all numbers\n",
    "    c(2, 4, 6, 8, 10, 12),   # even numbers\n",
    "    c(1, 3, 5, 7, 9, 11),    # odd numbers\n",
    "    c(3, 6, 9, 12),          # multiples of 3\n",
    "    c(4, 8, 12),             # multiples of 4\n",
    "    c(5, 10),                # multiples of 5\n",
    "    c(6, 12),                # multiples of 6\n",
    "    c(1, 4, 9)               # square numbers\n",
    "  ),\n",
    "  prior_math = 1) %>%\n",
    "  mutate(h_vec = map(h_members, ~set_member_indices(zeros, .x))) %>% \n",
    "  mutate(prior_math= prior_math/sum(prior_math)) %>% \n",
    "  mutate(h_str= map_chr(h_vec, indices_to_str)) %>% \n",
    "  select(h_str, prior_math) \n",
    "\n",
    "show_table(head(h_math))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b6b99c3c0dcc258d2518d0d174bfe69",
     "grade": false,
     "grade_id": "cell-ec974ffeafb11ba3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next we'll define `h_interval`, a hypothesis space of interval concepts (e.g. \"numbers between 2 and 5\", \"numbers between 6 and 12\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf7261af8ec25ccd2fc78390761856c6",
     "grade": false,
     "grade_id": "cell-dade20fe9bad71d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# enumerate all pairs (l, r) where l is less than r\n",
    "pairs <- t(combn(1:n, 2)) \n",
    "colnames(pairs) <- c(\"left\", \"right\")\n",
    "\n",
    "# a helper function that sets bits in H_VEC that include all numbers from LEFT to RIGHT \n",
    "pair_to_indices <- function(h_vec, left, right) {\n",
    "  h_vec[left:right] <- 1\n",
    "  return(h_vec)\n",
    "}\n",
    "\n",
    "h_interval <- tibble(left = 1:n, right = 1:n) %>% \n",
    "  bind_rows(as_tibble(pairs)) %>% \n",
    "  mutate(prior_interval = 1, h_vec = map2(left, right, ~pair_to_indices(zeros, .x, .y)))  %>% \n",
    "  mutate(prior_interval = prior_interval /sum(prior_interval)) %>% \n",
    "  mutate(h_str= map_chr(h_vec, indices_to_str)) %>% \n",
    "  select(h_str, prior_interval)\n",
    "\n",
    "# look at the last 5 hypotheses\n",
    "show_table(tail(h_interval, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc8a6d80566825839061c7ea82f892dd",
     "grade": false,
     "grade_id": "cell-d86ed91a520b70c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, we'll set up a hypothesis space `h_all` that includes all possible extensions of concept $C$ along with a uniform prior `h_uniform` over this space. The complete set of hypotheses in `h_all` is the hypothesis space $\\mathcal{H}$ we'll be using for subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cbbb44333f1ac432bdbd40ff22a6b35",
     "grade": false,
     "grade_id": "cell-80510e1341ff21d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h_all <-  expand.grid(replicate(n, 0:1, simplify = FALSE))\n",
    "colnames(h_all) <- paste(\"V\", 1:n, sep=\"\")\n",
    "# drop the empty hypothesis\n",
    "h_all <- h_all[-1,]\n",
    "h_all <- tibble(h_all) %>% \n",
    "  rowwise() %>% \n",
    "  mutate(h_vec = list(c_across(V1:V12))) %>% \n",
    "  ungroup() %>% \n",
    "  mutate(h_str= map_chr(h_vec, indices_to_str)) %>%\n",
    "  mutate(prior_uniform = 1)  %>% \n",
    "  mutate(prior_uniform = 1/sum(prior_uniform)) \n",
    "\n",
    "# look at the first 5 hypotheses. You'll see some additional columns V1:V12 and h_list that will be used later for\n",
    "# computing likelihood functions and model generalizations. Column V1 indicates whether or not 1 belongs to the \n",
    "# concept, and similarly for V2 through V12. h_vec is a vector indicating which numbers belong to the concept.\n",
    "show_table(head(h_all, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "439540b2a67068b59def41e25a1f62da",
     "grade": false,
     "grade_id": "cell-0d86f97f372a99f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'll combine `h_math`, `h_interval` and `h_all` to specify a single table `h` that specifies the entire hypothesis space $\\mathcal{H}$ along with four prior distributions. `prior_math` assigns nonzero probability only to the hypotheses in `h_math`, `prior_interval` assigns nonzero probability only to the hypotheses in `h_interval`, and `prior_uniform` assigns uniform probability to all possible hypotheses. The final prior `prior_combo` is a \"combination prior\" defined as the average of the three other priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d01834a5b19dec313369a43d7544984",
     "grade": false,
     "grade_id": "cell-480ef5270350d3e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h <- h_all %>% \n",
    "  left_join(h_math, by = \"h_str\") %>% \n",
    "  left_join(h_interval, by = \"h_str\") %>% \n",
    "  replace_na(list(prior_math = 0, prior_interval = 0)) %>% \n",
    "  mutate(prior_combo = (prior_math + prior_interval + prior_uniform) / 3 )\n",
    "\n",
    "show_table(head(h, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8f99ab7d9fad750034cfd4841debaaf",
     "grade": false,
     "grade_id": "cell-7c22b4a07b2d700d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Likelihood function $p(X|h)$\n",
    "We're ready to define the likelihood function. Following the notation in the Murphy reading, let $X$ be a list of positive examples of the concept. For instance, if we are told that 4 and 8 belong to the concept, then $X$ would be the list $[4, 8]$. The likelihood function $P(X|h)$ specifies the probability of observing $X$ given that the true concept is captured by hypothesis $h$.\n",
    "\n",
    "We'll consider two likelihood functions. *Strong sampling* assumes that the observations in $X$ are randomly sampled from the set of all positive examples of the concept, which means that $p(X|h) = \\left[ \\frac{1}{|h|} \\right]^n$, where $|h|$ is the size of hypothesis $h$. \n",
    "\n",
    "*Weak sampling* assumes that the examples were chosen by some process independent of $h$ and subsequently labeled as positive (i.e. members of the concept) or negative (not members of the concept). Under weak sampling it is possible to observe negative examples, but we're only going to consider cases in which all examples happen to be positive. Weak sampling corresponds to the likelihood function $p(X|h) = 1$ if all observations in $X$ are consistent with $h$, and 0 otherwise.\n",
    "\n",
    "### Question 2 (1  point)\n",
    "The code below sets up the likelihood function, but the definition of strong sampling is incorrect. Fix the code so that strong sampling is defined correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0864a593ec870f6856a4d9932427af20",
     "grade": false,
     "grade_id": "cell-0b0ce9ce8dca7fc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# H_VEC is a binary vector indicating which numbers belong to the concept, and X is a set of positive examples\n",
    "# ltype is a flag indicating whether we're assuming \"strong\" or \"weak\" sampling\n",
    "likelihood_fn <- function(h_vec, X, ltype) {\n",
    "  n <- length(X)\n",
    "  h_size <- sum(h_vec)\n",
    "  if ( sum(h_vec[X]) < n ) {\n",
    "    l <- 0\n",
    "  } else {\n",
    "    l <- switch(ltype,\n",
    "        strong = 1, # FIX THIS LINE\n",
    "        weak  = 1)\n",
    "  }\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "stop('No Answer Given!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8180d83b268f71624b03a75a2668736",
     "grade": true,
     "grade_id": "cell-1cb5bfa4ef10cb8a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we'll test likelihood_fn() by applying it to the observation set X = [3,4,5]. Make sure that\n",
    "# your function passes this test before you continue!\n",
    "X <- c(3,4,5)\n",
    "h_like_test <- h %>% \n",
    "    mutate(weak_like   = map_dbl(h_vec, ~likelihood_fn(.x, X, \"weak\"))) %>%    \n",
    "    mutate(strong_like = map_dbl(h_vec, ~likelihood_fn(.x, X, \"strong\")))  %>% \n",
    "    arrange(desc(weak_like))  %>% \n",
    "    pull(strong_like)  %>% \n",
    "    first()\n",
    "expect_equal(h_like_test, 0.037037, tolerance = 0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "177f3936b3b67e7d8d76db2c6981af78",
     "grade": false,
     "grade_id": "cell-013375657c531560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computing the posterior $p(h|X) \\propto p(X|h)p(h)$\n",
    "\n",
    "We can now combine the prior and likelihood to compute the posterior distribution. The prior $p(h)$  and likelihood $p(X|h)$ will both correspond to columns in our table, and if we were mechanically following the tabular approach we could also add columns for the observation set $X$, the joint distribution $p(X,h)$, and the marginal distribution $p(X)$. The posterior could then be computed by dividing the joint distribution column $p(X,h)$ by the marginal distribution column $p(X)$.\n",
    "\n",
    "A quicker way to compute the posterior, however, is to multiply the prior and likelihood columns elementwise (which produces the joint distribution $p(X,h)$) and to normalize the resulting column so that it sums to 1. This approach means that we don't actually have to compute the marginal distribution $p(X)$ directly --- instead we exploit the fact that the posterior $p(h|X)$ is a probability distribution and must sum to 1 over the hypothesis space.\n",
    "\n",
    "The code below uses `map_dbl()` to apply `likelihood_fn()` to each hypothesis in `h`. Because we've defined 4 priors and 2 likelihood functions there are 8 models in total, and we'll compute a posterior distribution for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a88b5df2d2694377da70109664c18868",
     "grade": false,
     "grade_id": "cell-55095c69ea7ebc4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# a function that processes a set of observations $X$ by first computing likelihoods STRONG_LIKE and WEAK_LIKE \n",
    "# according to strong and weak sampling, then combining these likelihoods with the four priors. For example, \n",
    "# WEAK_MATH is the posterior distribution for the model that assumes weak sampling and uses the mathematical \n",
    "# prior, and STRONG_COMBO is the model that assumes strong sampling and uses the combination prior\n",
    "process_X <- function(h, X) {\n",
    "  h_post <- h %>% \n",
    "    mutate(weak_like   = map_dbl(h_vec, ~likelihood_fn(.x, X, \"weak\"))) %>%    # likelihood column for weak sampling\n",
    "    mutate(strong_like = map_dbl(h_vec, ~likelihood_fn(.x, X, \"strong\"))) %>%  # likelihood column for strong sampling\n",
    "    # combine prior and likelihood \n",
    "    mutate(weak_math = weak_like * prior_math, strong_math = strong_like * prior_math, \n",
    "           weak_interval = weak_like * prior_interval, strong_interval = strong_like * prior_interval, \n",
    "           weak_uniform = weak_like * prior_uniform, strong_uniform = strong_like * prior_uniform,\n",
    "           weak_combo = weak_like * prior_combo, strong_combo = strong_like * prior_combo) %>% \n",
    "    # renormalize\n",
    "    mutate(weak_math = weak_math/sum(weak_math), strong_math = strong_math/sum(strong_math),\n",
    "           weak_interval = weak_interval/sum(weak_interval), strong_interval = strong_interval/sum(strong_interval),\n",
    "           weak_uniform = weak_uniform/sum(weak_uniform), strong_uniform = strong_uniform/sum(strong_uniform),\n",
    "           weak_combo = weak_combo/sum(weak_combo), strong_combo = strong_combo/sum(strong_combo))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87eeb3516e8f9e5cf56b358c9522a79c",
     "grade": false,
     "grade_id": "cell-26e04f9afbf0ad19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's now run the models. Suppose we observe that 4 and 8 belong to concept $C$ (i.e. $X = [4,8]$). We'll compute posterior distributions $p(h|X)$ for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0131858cf6d5edaad951f8defcd5d5c8",
     "grade": false,
     "grade_id": "cell-3e762dabcaaaf2a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h_post <- process_X(h, c(4,8))  %>% \n",
    "    arrange(desc(strong_math)) # arrange hypotheses in descending order according to the posterior for the strong_math model\n",
    "show_table(head(h_post, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58275a7ebcaee2b6d9b6c14a3c6afed7",
     "grade": false,
     "grade_id": "cell-6443e02f931690fd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 3 (1 point)\n",
    "\n",
    "Find the column `strong_math`, which shows the posterior $p(h|X)$ according to the `strong_math` model (strong sampling and mathematical prior). You should see that only three hypotheses have non-zero posterior probability according to this model -- what are the three hypotheses?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a59680847d190ace1f93771fd29148d8",
     "grade": true,
     "grade_id": "cell-10eee7c9c12136bf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87fb0a742bf70666f5547c6e3891ff29",
     "grade": false,
     "grade_id": "cell-6443e02f931690aa",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 4 (1 point)\n",
    "\n",
    "The observation set $X = [4,8]$ is equally consistent with \"multiples of 4\" and \"even numbers\", yet after observing $X$ you should see that the `strong_math` model thinks that \"multiples of 4\" is much more likely than \"even numbers.\" Explain why the model makes this inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66a1b8195252da450c1c43b41943bb7a",
     "grade": true,
     "grade_id": "cell-3642bf6872ab53c5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to inspect h_post in various ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e20ac9b75e65815f706884468ac3e132",
     "grade": false,
     "grade_id": "cell-a18e9e936d6a14a1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "To answer the next two questions, please use the `arrange()` function to sort `h_post` in different ways. You can use the code cell above to try out different sortings.\n",
    "\n",
    "### Question 5 (1 point)\n",
    "\n",
    "What is the hypothesis with greatest posterior probability according to the `strong_interval` model (ie the model that assumes strong sampling and uses the interval-based prior)? Explain why the `strong_interval` model makes this inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c7f06d1cb79baa45d8e3a1dcf29c5c2",
     "grade": true,
     "grade_id": "cell-fef5f6ebcddcda63",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f414021a8edc7748368429896a9f80a",
     "grade": false,
     "grade_id": "cell-a18e9e936d6a14f9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 6 (1 point)\n",
    "\n",
    "What is the hypothesis with greatest posterior probability according to the `strong_uniform` model (ie the model that assumes strong sampling and uses a uniform prior over the entire hypothesis space)? Explain why the `strong_uniform` model makes this inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0adb59ea7af7b5f0bc24f95fa12dd581",
     "grade": true,
     "grade_id": "cell-98c8c578645b97dd",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "933db52b7ba5b953dd611d7d6ad4863a",
     "grade": false,
     "grade_id": "cell-6ab5eb91745cca19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Posterior predictive distribution $P(y \\in C | X)$\n",
    "\n",
    "We've looked at the posterior distributions assigned by the models to individual hypotheses. Let's now look at how the models generalize across the full set of numbers. We'll compute and plot the posterior predictive distribution $P(y \\in C | X)$, which shows the probability that number $y$ belongs to concept $C$ after observing the examples in $X$. Because \"posterior predictive\" is a mouthful, we'll often refer to the \"predictive\" distribution for short.\n",
    "\n",
    "The predictive distribution can be computed by summing over the entire hypothesis space $\\mathcal{H}$: \\begin{align}\n",
    "P(y \\in C | X) &= \\sum_{h \\in \\mathcal{H}} P(y \\in C | h)P(h|X)  &(1)\\\\\n",
    "               &= \\sum_{h \\in \\mathcal{H_y}}P(h|X), & (2)\n",
    "\\end{align}\n",
    "where $\\mathcal{H_y}$ is the set of all hypotheses that include $y$.\n",
    "\n",
    "For example, after observing $X = [4,8]$ the `strong_math` model computes a posterior distribution over all hypotheses $h \\in \\mathcal{H}$. The probability that 12 also belongs to the concept corresponds to the sum of the posterior probabilities assigned to all hypotheses that include 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "914d5852cc19423b8b14a24dca36c667",
     "grade": false,
     "grade_id": "cell-a1536fa2cd0267fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the predictive distribution across all numbers from 1 to 12\n",
    "posterior_predictive <- function(h_post) {\n",
    "    \n",
    "  # we'll compute Equation 2 using matrix multiplication.\n",
    "  # h_mat is a binary matrix where the 12 rows represent the numbers from 1 to 12, and column i indicates which\n",
    "  # numbers belong to hypothesis i\n",
    "  h_mat <- h_post %>% \n",
    "    select(V1:V12) %>% \n",
    "    as.matrix() %>% \n",
    "    t()\n",
    "  \n",
    "  # the posterior predictive distribution for each model is now computed by multiplying h_mat by the posterior\n",
    "  # distribution for that model\n",
    "  \n",
    "  p_pred <- tibble(number  = 1:12, \n",
    "                   weak_math = as.vector(h_mat %*% h_post$weak_math),\n",
    "                   strong_math = as.vector(h_mat %*% h_post$strong_math),\n",
    "                   weak_interval = as.vector(h_mat %*% h_post$weak_interval),\n",
    "                   strong_interval = as.vector(h_mat %*% h_post$strong_interval),\n",
    "                   weak_uniform = as.vector(h_mat %*% h_post$weak_uniform),\n",
    "                   strong_uniform = as.vector(h_mat %*% h_post$strong_uniform),\n",
    "                   weak_combo = as.vector(h_mat %*% h_post$weak_combo),\n",
    "                   strong_combo = as.vector(h_mat %*% h_post$strong_combo),\n",
    "                   ) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe6b8ed9d55522f82c1458987593b6dd",
     "grade": false,
     "grade_id": "cell-e7dc3cf185dd67c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll also need a function to visualize the predictive distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60a1f5ce2e54a6e426d588ab186966d5",
     "grade": false,
     "grade_id": "cell-56dc9e00b9183fe0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# code to plot the posterior predictive distributions for all 8 models given the observations in X\n",
    "plot_posterior_predictive <- function(p_pred, X) {\n",
    "  p_pred_long <- p_pred %>% \n",
    "    pivot_longer(cols = c(\"weak_math\", \"strong_math\", \"weak_interval\", \"strong_interval\", \"weak_uniform\", \"strong_uniform\", \"weak_combo\", \"strong_combo\"),\n",
    "                 names_to = \"model\",\n",
    "                 values_to = \"generalization\") %>% \n",
    "    separate(model, c(\"likelihood\", \"prior\")) %>% \n",
    "    mutate(prior = factor(prior, levels = c(\"math\", \"interval\", \"uniform\", \"combo\")))\n",
    "  \n",
    "  pic <- p_pred_long %>%\n",
    "      ggplot(aes(x = number, y = generalization)) +\n",
    "      geom_col() +\n",
    "      scale_x_continuous(breaks=1:12) +  \n",
    "      facet_grid(likelihood ~prior) +\n",
    "      xlab(\"number\") +\n",
    "      ylab(paste(\"generalization after X =\", paste(X, collapse=\" \") ))\n",
    "\n",
    "  plot(pic)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94a5f4d8e911cecc242c150be66b7fff",
     "grade": false,
     "grade_id": "cell-b22521e5688ac707",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, let's define a wrapper function called `number_game` that takes an observation list $X$ as input, computes posterior distributions for all models and then plots predictive distributions for all models. We'll try it out by plotting predictive distributions for the observation list $X =[4,8]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b36207f46c703fc90b4bb5e6fc9672",
     "grade": false,
     "grade_id": "cell-935acce420ccc4a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "number_game <- function(h, X) {\n",
    "  h_post <- process_X(h, X)\n",
    "  p_pred <- posterior_predictive(h_post)\n",
    "  plot_posterior_predictive(p_pred, X)\n",
    "  return(h_post)\n",
    "}\n",
    "\n",
    "h_post <- number_game(h, c(4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc255ceedc36f93c1f520b49184df940",
     "grade": false,
     "grade_id": "cell-fa8de05f69e3a0e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the plot above, the first row shows inferences made by the four models that assume strong sampling, and the bottom row is for models that assume weak sampling. The four columns show inferences made by models that use the four different priors (mathematical, interval, uniform, and combination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10a5f9c584964468a594334cc33cae69",
     "grade": false,
     "grade_id": "cell-d71e3de952d8512d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's change the observation set $X$ and see what happens when $X = [4,7]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc824bc29db32e8c608c9e5b40c61626",
     "grade": false,
     "grade_id": "cell-d58bf64c725630b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h_post <- number_game(h, c(4,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9dc909f8f92d980e3f2aabc3b4b21213",
     "grade": false,
     "grade_id": "cell-fa38a26a76f401b3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 7 (1 point)\n",
    "\n",
    "After observing $X = [4,7]$, the two models which use the mathematical prior (leftmost column) are now certain that *all* numbers belong to the concept. Why do these models make this inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a98fed4a723e6402a719d38f82bb76d",
     "grade": true,
     "grade_id": "cell-61130142f1663b61",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f55c483e05c9063f8f08826bc9fd7d5b",
     "grade": false,
     "grade_id": "cell-82ac3a3a6d28b8ca",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 8 (1 point)\n",
    "\n",
    "You should see that the two models which use the uniform prior (third column) are unable to generalize beyond the observed examples. These models are able to \"memorize\" the observed examples (ie they pick up on the fact that 4 and 7 belong to the concept), but they don't make any distinctions at all between numbers outside of $X$. For these two models, why is the predictive distribution completely flat across all numbers that do not belong to $X$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6eebc278d183f895c398574d42d88ce",
     "grade": true,
     "grade_id": "cell-c6e761b6b3a558be",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2ab9e21e68a496b2bb8f16a31b0f0b0",
     "grade": false,
     "grade_id": "cell-f036cc559123fb9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at a case where $X$ includes a single example only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f46a197a188cc94d7ec68352a8db58e",
     "grade": false,
     "grade_id": "cell-21a6bbf896d3f5f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h_post <- number_game(h, c(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d852804e67a3b675a07b5872f48191ce",
     "grade": false,
     "grade_id": "cell-d258a1d524d695a0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Question 9 (1 point)\n",
    "\n",
    "Consider the predictions of the models with the `interval` prior (second column). Why is the predictive distribution asymmetric around the observed example 8: in particular, why does the predictive distribution assign higher probability to 7 than to 9?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1ed65687809fee91048099c50ec73cb",
     "grade": true,
     "grade_id": "cell-861b9efea5e56302",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98b03f871629488903effc1b98cb77e3",
     "grade": false,
     "grade_id": "cell-46b3b3e73b35fc70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now compare the plot we just made with the plot for the case when the same positive example is observed 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cba67d39346fc22a1bf72d51b5062dc6",
     "grade": false,
     "grade_id": "cell-e7ea6072e946dc95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "h_post <- number_game(h, c(8,8,8,8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a76e89cc36636815495740249133ad55",
     "grade": false,
     "grade_id": "cell-df80091fcb424c1e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "You should see that the predictive distributions in the top row (strong sampling) sharpen when a single positive example is repeated multiple times. For example, consider the `strong_combo` model. After observing 8 once, the model thinks that 4 is probably also a member of the concept, and the lowest prediction made for any number is just under 0.25. But after observing 8 a total of 5 times, the model is fairly sure that 8 is the *only* member of the concept -- the predictions for all other numbers are close to zero.\n",
    "\n",
    "### Question 10 (1 point)\n",
    "\n",
    "Your friend Eustace says that it doesn't make sense for a model to sharpen its predictions in this way. If $X = [8]$, you know that 8 belongs to the concept, and $X = [8,8,8,8,8]$ essentially gives you the same information --- both observation sets are really giving you one piece of information (ie that 8 belongs to the concept). Respond to Eustace and explain why it makes sense for a model to change its inferences as the same example is repeatedly observed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09cc6dd3f7d65024f98e585a92be2cdf",
     "grade": true,
     "grade_id": "cell-dfb0f39534158354",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
