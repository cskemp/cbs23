{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6673abc6c6832fd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CBS Week 3 Tutorial: Causal reasoning\n",
    "## Semester 2 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9522d4829430e8f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.6     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.1     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "nimble version 0.11.1 is loaded.\n",
      "For more information on NIMBLE and a User Manual,\n",
      "please visit http://R-nimble.org.\n",
      "\n",
      "\n",
      "Attaching package: ‘nimble’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    simulate\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘testthat’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    is_null\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(nimble)\n",
    "library(testthat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c424dd26b502c5bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This tutorial focuses on causal Bayesian networks, and will give you some practice in modeling inferences about interventions.\n",
    "\n",
    "Bayes nets are often specified by thinking about causal relationships --- for example, the edge from Robbery to Alarm in last week's network was intended to capture the fact that a robbery causes the alarm to sound. When developing a Bayes net, we suggested that you should only include arrows that capture causal relationships. But the formalism of Bayes nets actually makes no causal assumptions, and there are valid Bayes nets where the arrows do not capture causal relationships.\n",
    "\n",
    "Unlike regular Bayes nets, a  *causal* Bayes net has arrows that capture causal relationships. Because of this property a causal Bayes net supports inferences about interventions: for example, an inference about how the other variables in a network might change if we reach in and alter the value of one variable.\n",
    "\n",
    "In this tutorial we'll work with two causal Bayes nets from Figure 6-6 of Hagmayer et al, [Causal reasoning through intervention]( https://www.ucl.ac.uk/lagnado-lab/publications/lagnado/intervention%20hagmayer%20et%20al.pdf ). Both networks specify causal relationships between three hormones,  and the level of each hormone is either normal (1) or elevated (2).   In the common cause model, elevated levels of Pixin (P = 2) cause elevated levels of both Sonin and Xanthan. In the chain model, elevated levels of Sonin (S = 2) cause elevated levels of Pixin (P = 2), which in turn cause elevated levels of Xanthan (X = 2). The probability distributions shown include probabilities like `P(P=2)` which is slightly confusing --- here the first `P` is the probability symbol and the second is the variable for Pixin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4047cf766262bdfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<figure>\n",
    "  <img src=\"images/commoncause_chain_models.png\" alt=\"commoncause_chain_models\" style=\"width:50%\">\n",
    "  <figcaption  class=\"figure-caption text-center\">Figure 1: Two models specifying causal relationships between three hormones. (a) Common cause model (b) Chain model. This figure is a redrawn version of Fig 6-6 of Hagmayer et al, Causal reasoning through intervention.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a9859ce55ff9598",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The two models were deliberately chosen to capture the same joint distribution over the three variables. \n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Write down the joint distribution by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ec541aac420fe33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 8 x 4\u001b[39m\n",
      "      P     S     X p_P_S_X\n",
      "  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m     1     1     1   0.405\n",
      "\u001b[90m2\u001b[39m     1     1     2   0.045\n",
      "\u001b[90m3\u001b[39m     1     2     1   0.045\n",
      "\u001b[90m4\u001b[39m     1     2     2   0.005\n",
      "\u001b[90m5\u001b[39m     2     1     1   0.005\n",
      "\u001b[90m6\u001b[39m     2     1     2   0.045\n",
      "\u001b[90m7\u001b[39m     2     2     1   0.045\n",
      "\u001b[90m8\u001b[39m     2     2     2   0.405\n"
     ]
    }
   ],
   "source": [
    "# Fix the distribution below so that it reflects the joint distribution P(P,S,X) captured by both the Common Cause and Chain models. The column labelled P_P_S_X currently contains zeros but you should replace these with the correct probabilities.\n",
    "joint <- tibble(P = c(1,1,1,1,2,2,2,2), \n",
    "                S = c(1,1,2,2,1,1,2,2), \n",
    "                X = c(1,2,1,2,1,2,1,2), \n",
    "                p_P_S_X = c(0,0,0,0,0,0,0,0) )\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "joint$p_P_S_X = c(0.405, 0.045, 0.045, 0.005, 0.005, 0.045, 0.045, 0.405)    \n",
    "### END SOLUTION\n",
    "\n",
    "print(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2897d296a52cdd33",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expect_equal(sum(joint$p_P_S_X),  1) \n",
    "### BEGIN HIDDEN TESTS\n",
    "joint_sorted <- joint %>% arrange(P, S, X)\n",
    "\n",
    "expect_equal(joint_sorted$p_P_S_X, \n",
    "            c(0.405, 0.045, 0.045, 0.005, 0.005, 0.045, 0.045, 0.405),     \n",
    "            tolerance = 0.001)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b2accd1185f8929",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Waldmann and Hagmayer (2005) carried out an experiment in which they asked participants to reason about the two causal models in Figure 1 using a scenario involving hormone levels of chimpanzees.  Participants first went through a training phase in which they learned either the Common Cause model or the Chain model. The training included a written description of the model---e.g. common-cause participants were told that an increased level of the hormone Pixin causes increases in the level of both Sonin and Xanthan. The training also included observations of the hormone levels of 20 chimpanzees, which allowed participants to estimate the parameters of the causal networks. For example, half of these 20 chimpanzees had elevated levels of Pixin, allowing participants to figure out that $P(P=2) = 0.5$.\n",
    "\n",
    "Participants were then asked to reason about a new set of 20 previously unseen chimpanzees. They were asked about both hypothetical *observations* and hypothetical *interventions*. The observation questions asked people to imagine that Sonin had been observed to be either elevated or normal in each of the 20 new chimpanzees, and to estimate the number of these chimpanzees that would have elevated levels of Xanthan. In terms of our models, these two estimates correspond to the probabilities $P(X=2|S=2)$ and  $P(X=2|S=1)$.  The intervention questions were similar but asked people to imagine that the Sonin levels of all chimpanzees had been determined by an injection (ie an intervention) instead of just being observed. The corresponding two probabilities are $P(X=2|do(S=2))$ and  $P(X=2|do(S=1))$ where we've used Pearl's $\\text{do}(\\cdot)$ operator to indicate that the value of S is set by an intervention instead of merely being observed. \n",
    "\n",
    "The light grey bars in the figure below show average human inferences, and the dark grey bars show model predictions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-756b6c2ca7e3e4de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<figure>\n",
    "  <img src=\"images/model_human_inferences.png\" alt=\"model_human_inferences\" style=\"width:50%\">\n",
    "  <figcaption  class=\"figure-caption text-center\">Figure 2: Results of experiment carried out by Waldmann and Hagmayer (2005). The y axis shows the number of animals out of a set of 20 that were estimated to have elevated levels of Xanthan. In the Observation condition, the two groups of bars show results when Sonin is observed to be either elevated or normal. In the Intervention condition, the two groups of bars show results when the animals were given injections that either made the Sonin level elevated or normal. This figure is taken from Fig 6-7 of Hagmayer et al, Causal reasoning through intervention.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57017d1d20a7c6bf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Think about how you would have responded if you were a participant. For the common cause model, participants gave a higher estimate of $P(X=2|S=2)$ than  $P(X=2|do(S=2))$. Would you have done the same? Why or why not?  For the chain model, participants indicated that  $P(X=2|S=2)$ and $P(X=2|do(S=2))$ were roughly the same. Would you have made the same inference? Why?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "For the common cause model, it makes sense that $P(X=2|S=2)$ is high, because the elevated level of Sonin was probably caused by an elevated level of Pixin, which in turn would cause an elevated level of Xanthan. It also makes sense that $P(X=2|do(S=2))$ is around 0.5.  In this case the elevated level of Sonin can be attributed to the intervention, and knowing that Sonin was elevated because of an injection provides no information about what the levels of Pixin and Xanthan are likely to be. In the absence of any other information, it makes sense to go with the base rate (ie in general 50\\% of animals have elevated levels of Xanthan).\n",
    "\n",
    "For the chain model, an elevated level of Sonin causes an elevated level of Pixin, which in turn causes an elevated level of Xanthan. The same conclusion holds regardless of whether the Sonin level was naturally elevated or elevated because of an injection. It therefore makes sense that  $P(X=2|S=2)$ and $P(X=2|do(S=2))$ are both high and both roughly the same. \n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6f44f2352d630ff1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57017d1d20a7c6bf2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Observation questions\n",
    "\n",
    "We'll try to replicate the model predictions using NIMBLE. First let's compute predictions for the observation questions. We'll start with the common cause model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e22e8a17c0a0de5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "commoncause_code <- nimbleCode({\n",
    "  # dcat specifies a discrete categorical distribution\n",
    "  p ~ dcat(P_cpd[1:2])\n",
    "  s ~ dcat(S_cpd[p,1:2])\n",
    "  x ~ dcat(X_cpd[p,1:2])\n",
    "})\n",
    "\n",
    "commoncause_data <- list(\n",
    "  P_cpd = c(0.5, 0.5), \n",
    "  S_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2)),\n",
    "  X_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $P(X=2|S=1)$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-533f633b98a765e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "defining model...\n",
      "\n",
      "building model...\n",
      "\n",
      "setting data and initial values...\n",
      "\n",
      "running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n",
      "\n",
      "\n",
      "checking model sizes and dimensions...\n",
      "\n",
      "\n",
      "checking model calculations...\n",
      "\n",
      "model building finished.\n",
      "\n",
      "compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n",
      "\n",
      "compilation finished.\n",
      "\n",
      "running chain 1...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------|-------------|-------------|-------------|\n",
      "|-------------------------------------------------------|\n",
      "[1] \"For the common cause model, P(X=2|S=1) ≈ 0.1943\"\n"
     ]
    }
   ],
   "source": [
    "commoncause_data$s= 1\n",
    "samples <- nimbleMCMC(\n",
    "  code = commoncause_code,\n",
    "  data = commoncause_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "\n",
    "# function for turning a bag of samples into a sample-based posterior on x\n",
    "x_posterior <- function( samples ) {\n",
    "  ps <- samples %>% \n",
    "    as_tibble() %>% \n",
    "    group_by(x) %>% \n",
    "    summarize(count = n(), .groups = \"drop\") %>%  \n",
    "    mutate(prob = count/sum(count))               \n",
    "  return(ps)\n",
    "}\n",
    "\n",
    "p_x2_given_s1_cc <- x_posterior(samples)$prob[2]\n",
    "print(paste0('For the common cause model, P(X=2|S=1) ≈ ', as.character(p_x2_given_s1_cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-681ed9f9a19d75c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And now compute $P(X=2|S=2)$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88735abf3630269f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "defining model...\n",
      "\n",
      "building model...\n",
      "\n",
      "setting data and initial values...\n",
      "\n",
      "running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n",
      "\n",
      "\n",
      "checking model sizes and dimensions...\n",
      "\n",
      "\n",
      "checking model calculations...\n",
      "\n",
      "model building finished.\n",
      "\n",
      "compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n",
      "\n",
      "compilation finished.\n",
      "\n",
      "running chain 1...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------|-------------|-------------|-------------|\n",
      "|-------------------------------------------------------|\n",
      "[1] \"For the common cause model, P(X=2|S=2) ≈ 0.8172\"\n"
     ]
    }
   ],
   "source": [
    "commoncause_data$s= 2\n",
    "samples <- nimbleMCMC(\n",
    "  code = commoncause_code,\n",
    "  data = commoncause_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "\n",
    "p_x2_given_s2_cc <- x_posterior(samples)$prob[2]\n",
    "print(paste0('For the common cause model, P(X=2|S=2) ≈ ', as.character(p_x2_given_s2_cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f060c1d35eea055",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3 \n",
    "\n",
    "Use NIMBLE to compute $P(X=2|S=1)$ and  $P(X=2|S=2)$ according to the chain model in Figure 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-104b8577bd572d7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "defining model...\n",
      "\n",
      "building model...\n",
      "\n",
      "setting data and initial values...\n",
      "\n",
      "running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n",
      "\n",
      "\n",
      "checking model sizes and dimensions...\n",
      "\n",
      "\n",
      "checking model calculations...\n",
      "\n",
      "model building finished.\n",
      "\n",
      "compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n",
      "\n",
      "compilation finished.\n",
      "\n",
      "running chain 1...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------|-------------|-------------|-------------|\n",
      "|-------------------------------------------------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "defining model...\n",
      "\n",
      "building model...\n",
      "\n",
      "setting data and initial values...\n",
      "\n",
      "running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... \n",
      "\n",
      "\n",
      "checking model sizes and dimensions...\n",
      "\n",
      "\n",
      "checking model calculations...\n",
      "\n",
      "model building finished.\n",
      "\n",
      "compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.\n",
      "\n",
      "compilation finished.\n",
      "\n",
      "running chain 1...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------|-------------|-------------|-------------|\n",
      "|-------------------------------------------------------|\n",
      "[1] \"For the chain model, P(X=2|S=1) ≈ 0.1824\"\n",
      "[1] \"For the chain model, P(X=2|S=2) ≈ 0.8203\"\n"
     ]
    }
   ],
   "source": [
    "# Redefine these two variables\n",
    "p_x2_given_s1_chain <- 0\n",
    "p_x2_given_s2_chain <- 0\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "chain_code <- nimbleCode({\n",
    "  # dcat specifies a discrete categorical distribution\n",
    "  s ~ dcat(S_cpd[1:2])\n",
    "  p ~ dcat(P_cpd[s,1:2])\n",
    "  x ~ dcat(X_cpd[p,1:2])\n",
    "})\n",
    "\n",
    "chain_data <- list(\n",
    "  S_cpd = c(0.5, 0.5), \n",
    "  P_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2)),\n",
    "  X_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2))\n",
    ")\n",
    "\n",
    "chain_data$s= 1\n",
    "samples <- nimbleMCMC(\n",
    "  code = chain_code,\n",
    "  data = chain_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_s1_chain <- x_posterior(samples)$prob[2]\n",
    "\n",
    "chain_data$s= 2\n",
    "samples <- nimbleMCMC(\n",
    "  code = chain_code,\n",
    "  data = chain_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_s2_chain <- x_posterior(samples)$prob[2]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(paste0('For the chain model, P(X=2|S=1) ≈ ', as.character(p_x2_given_s1_chain)))\n",
    "print(paste0('For the chain model, P(X=2|S=2) ≈ ', as.character(p_x2_given_s2_chain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c02a1728b25de8aa",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expect_lt(p_x2_given_s1_chain, 1)\n",
    "expect_gt(p_x2_given_s1_chain, 0)\n",
    "expect_lt(p_x2_given_s2_chain, 1)\n",
    "expect_gt(p_x2_given_s2_chain, 0)\n",
    "### BEGIN HIDDEN TESTS\n",
    "expect_equal(p_x2_given_s1_chain, 0.2, tolerance = 0.03)\n",
    "expect_equal(p_x2_given_s2_chain, 0.8, tolerance = 0.03)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-060a2146beb96ca3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Intervention questions\n",
    "\n",
    "Now compute model predictions for the intervention questions. The probabilities to estimate are \n",
    "$P(X=2|\\text{do}(S=1))$ and  $P(X=2|\\text{do}(S=2))$, where we've used Pearl's  $\\text{do}(\\cdot)$ operator to indicate that the values of $S$ are set by an intervention instead of simply observed.\n",
    "\n",
    "If a package like NIMBLE supported interventions we could reuse our `nimbleCode()` specifications of the two models and include a `data` argument formulated using the `do()` operator. For example, something like:\n",
    "\n",
    "\n",
    "```R\n",
    "commoncause_intervention_data <- list(\n",
    "  s = do(1),\n",
    "  P_cpd = c(0.5, 0.5), \n",
    "  S_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2)),\n",
    "  X_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2))\n",
    ")\n",
    "```\n",
    "\n",
    "In reality, NIMBLE doesn't support the `do()` operator, so we'll handle interventions by transforming the original network into a *manipulated* network that captures the intervention.  Recall that graph manipulation involves cutting all arrows that lead into the node that is the target of the intervention, and adjusting the CPD of this node to reflect that its value is set by external means. The intervention `do(S=2)` produces the following manipulated networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48009885ff0d2278",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<figure>\n",
    "  <img src=\"images/commoncause_chain_intervention.png\" alt=\"commoncause_chain_intervention\" style=\"width:50%\">\n",
    "  <figcaption  class=\"figure-caption text-center\">Figure 3: The models from Figure 1 have been manipulated to reflect an intervention (symbolized here by a hammer) that fixes the level of Sonin to 2.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee6e36cc312b39a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Use NIMBLE to compute $P(X=2|do(S=1))$ and  $P(X=2|do(S=2))$ according to the common cause model. You'll need to define a new model that matches Figure 3a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-871dad4a5f3bc96b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Redefine these two variables\n",
    "p_x2_given_do_s1_cc<- 0\n",
    "p_x2_given_do_s2_cc<- 0\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "cc_intervention_code <- nimbleCode({\n",
    "  # dcat specifies a discrete categorical distribution\n",
    "  s ~ dcat(S_cpd[1:2])\n",
    "  p ~ dcat(P_cpd[1:2])\n",
    "  x ~ dcat(X_cpd[p,1:2])\n",
    "})\n",
    "\n",
    "cc_intervention_data <- list(\n",
    "  S_cpd = c(0, 1), \n",
    "  P_cpd = c(0.5, 0.5), \n",
    "  X_cpd =  array(c(0.9, 0.1, 0.1, 0.9), dim = c(2,2))\n",
    ")\n",
    "\n",
    "cc_intervention_data$s= 1\n",
    "samples <- nimbleMCMC(\n",
    "  code = cc_intervention_code,\n",
    "  data = cc_intervention_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_do_s1_cc <- x_posterior(samples)$prob[2]\n",
    "\n",
    "cc_intervention_data$s= 2\n",
    "samples <- nimbleMCMC(\n",
    "  code = cc_intervention_code,\n",
    "  data = cc_intervention_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_do_s2_cc<- x_posterior(samples)$prob[2]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(paste0('For the common cause model, P(X=2|do(S=1)) ≈ ', as.character(p_x2_given_do_s1_cc)))\n",
    "print(paste0('For the common cause model, P(X=2|do(S=2)) ≈ ', as.character(p_x2_given_do_s2_cc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-65cf46426aca737e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expect_lt(p_x2_given_do_s1_cc, 1)\n",
    "expect_gt(p_x2_given_do_s1_cc, 0)\n",
    "expect_lt(p_x2_given_do_s2_cc, 1)\n",
    "expect_gt(p_x2_given_do_s2_cc, 0)\n",
    "### BEGIN HIDDEN TESTS\n",
    "expect_equal(p_x2_given_do_s1_cc, 0.5, tolerance = 0.03)\n",
    "expect_equal(p_x2_given_do_s2_cc, 0.5, tolerance = 0.03)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62b6a7ff6153d6cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Use NIMBLE to compute $P(X=2|do(S=1))$ and  $P(X=2|do(S=2))$ according to the chain model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a713d1a6bffdf488",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Redefine these two variables\n",
    "p_x2_given_do_s1_chain <- 0\n",
    "p_x2_given_do_s2_chain <- 0\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# The manipulated chain model is identical to the original chain model, so we can reuse chain_code and chain_data. We could just set p_x2_given_do_s1_chain <- p_x2_given_s1_chain, but let's run NIMBLE again because we'll get a slightly different answer each time we carry out inference by sampling.\n",
    "\n",
    "chain_data$s= 1\n",
    "samples <- nimbleMCMC(\n",
    "  code = chain_code,\n",
    "  data = chain_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_do_s1_chain <- x_posterior(samples)$prob[2]\n",
    "\n",
    "chain_data$s= 2\n",
    "samples <- nimbleMCMC(\n",
    "  code = chain_code,\n",
    "  data = chain_data,\n",
    "  monitors =  c(\"p\", \"s\", \"x\"),\n",
    "  inits = list(p=1, x=1),\n",
    ")    \n",
    "p_x2_given_do_s2_chain <- x_posterior(samples)$prob[2]\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(paste0('For the common cause model, P(X=2|do(S=1)) ≈ ', as.character(p_x2_given_do_s1_chain)))\n",
    "print(paste0('For the common cause model, P(X=2|do(S=2)) ≈ ', as.character(p_x2_given_do_s2_chain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d6d5378cffba7c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "expect_lt(p_x2_given_do_s1_chain, 1)\n",
    "expect_gt(p_x2_given_do_s1_chain, 0)\n",
    "expect_lt(p_x2_given_do_s2_chain, 1)\n",
    "expect_gt(p_x2_given_do_s2_chain, 0)\n",
    "### BEGIN HIDDEN TESTS\n",
    "expect_equal(p_x2_given_do_s1_chain, 0.2, tolerance = 0.03)\n",
    "expect_equal(p_x2_given_do_s2_chain, 0.8, tolerance = 0.03)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-261fe92ea765b6fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Summary of model predictions\n",
    "\n",
    "Let's gather all of the NIMBLE estimates in an order that matches Figure 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bcf9b136fb5d965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "inference_order =  c(\"cc_i_i\", \"cc_i_l\", \"cc_o_i\", \"cc_o_l\", \"chn_i_i\", \"chn_i_l\", \"chn_o_i\",  \"chn_o_l\")\n",
    "\n",
    "nimblepreds <- tibble(cc_i_i=p_x2_given_do_s2_cc,  \n",
    "                      cc_i_l=p_x2_given_do_s1_cc,  \n",
    "                      cc_o_i=p_x2_given_s2_cc,  \n",
    "                      cc_o_l=p_x2_given_s1_cc,  \n",
    "                      chn_i_i=p_x2_given_do_s2_chain,  \n",
    "                      chn_i_l=p_x2_given_do_s1_chain,  \n",
    "                      chn_o_i=p_x2_given_s2_chain,  \n",
    "                      chn_o_l=p_x2_given_s1_chain) %>% \n",
    "                gather() %>% \n",
    "                mutate(inference= factor(key, levels=inference_order), probability=value) %>% \n",
    "                select(inference, probability)\n",
    "\n",
    "nimblepredplot <- nimblepreds %>% \n",
    "  ggplot(aes(x=inference, y = probability)) +\n",
    "  geom_col() +\n",
    "  ylab(\"model prediction\")\n",
    "\n",
    "print(nimblepredplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-120308f53d63f2c01",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "The order of the bars from left to right matches the order in Figure 2. For example, `cc_i_i` is short for common cause/intervention/increasing and `cc_i_l` is short for common cause/intervention/lowering. \n",
    "\n",
    "Check that the model predictions line up with the model predictions in Figure 2. If not, we've done something wrong!\n",
    "\n",
    "## Optional Exercises (if time permits)\n",
    "\n",
    "1. Is it surprising that two different Bayes nets can specify the same joint distribution? If you show me any Bayes net can I always give you a different Bayes net that captures the same joint distribution?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "Having two Bayes nets that capture the same joint distribution is not unusual. If you give me a joint distribution over two or more variables, I can always write down different Bayes nets that capture this distribution. \n",
    "\n",
    "For example, suppose you give me a joint distribution $P(a,b)$. One Bayes net that captures this distribution is $a \\rightarrow b$, which corresponds to the factorization $P(a,b)=P(a)P(b|a)$.  A second Bayes net that captures the same joint distribution is $a \\leftarrow b$, which corresponds to the factorization $P(a,b)=P(b)P(a|b)$. \n",
    "\n",
    "It follows that if you give me a Bayes net where the edges capture causal mechanisms, I can always construct a different Bayes net that captures the same joint distribution but where the edges do not capture causal mechanisms. For example, if you give me the network $\\text{breast cancer} \\rightarrow \\text{mammogram result}$ we saw in class, I can give you a network \n",
    "$\\text{breast cancer} \\leftarrow \\text{mammogram result}$ that captures the same joint distribution over the two variables. This example highlights the fact that a joint distribution over a set of variables is not enough to capture causal relationships between the variables.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3ab09969c3bd48fa",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-120308f53d63f2c02",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "2. In the week 3 lecture we talked about causal structure learning, or learning the causal relationships that hold between a set of variables.  Imagine that you do not know the causal relationships between Pixin, Sonin and Xanthan. To attempt to figure this out you measure hormone levels from a large number of chimpanzees. For example, you might discover that the first chimp has elevated levels of all three hormones, that the second has normal levels of Sonin but elevated levels of Pixin and Xanthan, and so on. Will taking measurements in this way allow you to figure out the causal relationships between the three hormones? Why or why not?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "Taking measurements in this way will not allow you to figure out the causal relationships between the three hormones. The measurements will allow you to estimate the joint distribution over the three variables, but as just discussed knowing the joint distribution over a set of variables isn't enough to figure out the causal relationships between the variables.\n",
    "\n",
    "In particular, measuring hormone levels from a large number of chimpanzees will not allow you to tell the difference between the common cause and chain models in Figure 1. Both models capture exactly the same joint distribution over variables, so knowing the joint distribution isn't enough to tell you which model is correct.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2307351c05992730",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-120308f53d63f2c03",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "3. If your answer to the previous question is no, how might you figure out the causal relationships between the hormones? \n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "It's often said that experiments (ie investigations where you intervene and manipulate the value of some variable) are good for figuring out causal relationships, and the same point applies here. \n",
    "\n",
    "For example,  Figure 2 shows that the two models make different predictions about what will happen after intervening to set $S=2$. If you repeatedly make this intervention and observe that $X = 2$ around 80% of the time, i.e. $P(X=2|do(S=2)) \\approx 0.8$, you could conclude that your experimental results were consistent with the common cause model. If you observed instead that   $P(X=2|do(S=2)) \\approx 0.5$, you would conclude that your experimental results were consistent with the chain model.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-49756ef17fee43b1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
