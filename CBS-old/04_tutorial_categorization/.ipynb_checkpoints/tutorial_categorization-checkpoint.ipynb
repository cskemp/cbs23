{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "685eb07d1b93fd2dfc5eb2ecdd1eb069",
     "grade": false,
     "grade_id": "cell-6bd8c1bbe0aeb59d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CBS Week 4 Tutorial: Categorization\n",
    "## Semester 2 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3f841537929ea887d82a44b81d960bc",
     "grade": false,
     "grade_id": "cell-d2ff8df11e2671b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.2     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "\n",
      "Attaching package: ‘janitor’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    chisq.test, fisher.test\n",
      "\n",
      "\n",
      "nimble version 0.11.1 is loaded.\n",
      "For more information on NIMBLE and a User Manual,\n",
      "please visit http://R-nimble.org.\n",
      "\n",
      "\n",
      "Attaching package: ‘nimble’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    simulate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(janitor)\n",
    "library(nimble)\n",
    "options(repr.plot.width=10, repr.plot.height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2936310fedba20086a726e5693665d58",
     "grade": false,
     "grade_id": "cell-f53ed9dd873ec06d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This tutorial focuses on exemplar and prototype models of categorization. To keep things simple we'll focus on a one-dimensional example. Imagine a set of objects that vary along one dimension --- for example the dimension of \"spikiness\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e252e0135c635447a29b4e2992940dba",
     "grade": false,
     "grade_id": "cell-1ee6fbd3058d94a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<figure>\n",
    "  <img src=\"images/spikiness.jpg\" alt=\"spikiness\" style=\"width:50%\">\n",
    "  <figcaption  class=\"figure-caption text-center\">\n",
    "Figure 1: Objects that vary along the dimension of spikiness. From Gibson, Rogers & Zhu (2013), Human semi-supervised learning\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "271c27037aba6e79275062786bd0a3dc",
     "grade": false,
     "grade_id": "cell-b15a09cfe0e4170b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll use some data where 9 objects are organized into two categories. Let `x` indicate the spikiness of each object, and `z` denote its category label. Because we're looking at a *supervised* problem, the category label of each object is known. In this made-up data set, objects that are relatively spiky or relatively smooth belong to category 1, and objects between these extremes belong to category 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52e2527d72932f4e9deb6320ce127bdc",
     "grade": false,
     "grade_id": "cell-970c9426abed15cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 9 x 2\u001b[39m\n",
      "      x z    \n",
      "  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m  -\u001b[31m1\u001b[39m   1    \n",
      "\u001b[90m2\u001b[39m  -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m8\u001b[39m 1    \n",
      "\u001b[90m3\u001b[39m  -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m 1    \n",
      "\u001b[90m4\u001b[39m   1.5 1    \n",
      "\u001b[90m5\u001b[39m   1.7 1    \n",
      "\u001b[90m6\u001b[39m   0.6 2    \n",
      "\u001b[90m7\u001b[39m   0.8 2    \n",
      "\u001b[90m8\u001b[39m   1   2    \n",
      "\u001b[90m9\u001b[39m   1.1 2    \n"
     ]
    }
   ],
   "source": [
    "data_1d <- tibble(x = c(-1.0, -0.8, -0.6, 1.5, 1.7, 0.6, 0.8, 1.0, 1.1),\n",
    "                  z = factor( c(1, 1, 1, 1, 1, 2, 2, 2, 2) ))\n",
    "print(data_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f65cdb35ad2d83eaaf5483bf41f2cf04",
     "grade": false,
     "grade_id": "cell-ab8cb9bfd4d24ce4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exemplar model\n",
    "\n",
    "Given a set of examples where $z=1$, an exemplar model computes the probability density for category 1 (ie $p(x|z=1)$) by dropping a Gaussian kernel (ie a Gaussian bump) on each example, adding up all these kernels, and renormalizing to make sure that the density integrates to 1. \n",
    "\n",
    "Let's plot densities for both category 1 (`z=1`) and category 2 (`z=2`). We'll assume that the standard deviation of each Gaussian bump (also known as the kernel bandwidth) is `mybw = 0.3`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dea47b56e62bac29a942812c88fb2c0",
     "grade": false,
     "grade_id": "cell-3fb63d2a4fd4053d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "                                      # \"nrd\" specifies a method for choosing the bandwidth if \n",
    "                                      #  this parameter is not supplied\n",
    "exemplar_plot_1d <- function(data, bw=\"nrd\") {\n",
    "  e_plot <-  data %>% \n",
    "    ggplot(aes(x = x, color = z, group = z)) +\n",
    "    geom_density(bw = bw) +\n",
    "    geom_point(aes(x=x, y=0)) +\n",
    "    labs(color='category (z)') +\n",
    "    ylab(\"density p(x|z)\")\n",
    "}\n",
    "\n",
    "mybw = 0.3\n",
    "eplot_mybw <- exemplar_plot_1d(data_1d, bw=mybw) \n",
    "print(eplot_mybw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d480cdfec4ec16b4338eaefb65688983",
     "grade": false,
     "grade_id": "cell-86cee6861f848ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If we make the kernel bandwidth much smaller you can tell that the category densities are created by adding up kernels centred on each example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ced5888489345b677da49403786ed61",
     "grade": false,
     "grade_id": "cell-0ac7547429d64770",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(exemplar_plot_1d(data_1d, bw=0.03) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2813248108f7c6386fa7e2463d3cacee",
     "grade": false,
     "grade_id": "cell-de8ab7399c21ca1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Suppose that we're given a new object with $x = 0$ and we want to know the probability that this object belongs to category 1. More generally, we might want to compute a classification function $P(z=1|x)$ that we can use to estimate the probability that a new object anywhere along the dimension belongs to category 1.\n",
    "\n",
    "Bayes rule tells us that $P(z=1|x) \\propto P(x|z) P(z=1)$. Even though we plotted $p(x|z=1)$ and $p(x|z=2)$ in Figure 2 we don't have these curves stored as data structures. So let's set up a function for computing the likelihood $P(x|z)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9c55803af1cdf9af3779b17f019e65b",
     "grade": false,
     "grade_id": "cell-567a82f7aad35cb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute p(XNEW|z=CATEGORY)  based on the observations in DATA\n",
    "p_x_given_z <- function(data, category, xnew, bw = mybw){\n",
    "  newval <- data %>% \n",
    "    filter(z == category) %>% \n",
    "    mutate(k_val = dnorm(xnew, mean = x, sd = bw)) %>% \n",
    "    summarize(mean_k_val = mean(k_val)) %>% \n",
    "    pull()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89b9970d21059f61664a9f5755cb60b0",
     "grade": false,
     "grade_id": "cell-c128575236e9a8c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll also set up a function to compute the prior.  We'll assume that $P(z=1)$ corresponds to the proportion of observed examples that belong to category 1. For the data set we've been working with $P(z=1) = \\frac{5}{9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c4e6562662ab2c77ae9f0993d9d8446",
     "grade": false,
     "grade_id": "cell-1387030e95cb6893",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute p(z=CATEGORY) based on the observations in DATA\n",
    "p_z <- function(data, category){\n",
    "  sum(data$z == category)/nrow(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe17104407e952861d58a699c1e0284d",
     "grade": false,
     "grade_id": "cell-6af581cee44ee0eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll now multiply the prior and likelihood then renormalize to compute $p(z=1|x)$ over a grid of points between -3 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3064ff1ec6b436655e6447aab035892d",
     "grade": false,
     "grade_id": "cell-f4810f7a4a945cbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "classification_curve <- function(data, bw = mybw) {\n",
    "  classifications <- tibble(x = seq(-3, 3, 0.01)) %>% \n",
    "    # compute p(z) for all x\n",
    "    mutate(p_z1 = p_z(data, 1)) %>% \n",
    "    mutate(p_z2 = p_z(data, 2)) %>% \n",
    "    # compute p(x|z) \n",
    "    mutate(p_x_given_z1 = map_dbl(x, ~p_x_given_z(data, 1, ., bw))) %>% \n",
    "    mutate(p_x_given_z2 = map_dbl(x, ~p_x_given_z(data, 2, ., bw))) %>% \n",
    "    # compute p(z|x) up to normalizing constant\n",
    "    mutate(p_z1_given_x = p_x_given_z1*p_z1) %>% \n",
    "    mutate(p_z2_given_x = p_x_given_z2*p_z2) %>% \n",
    "    # normalize p(z|x) \n",
    "    mutate(p_z1_given_x = p_z1_given_x /(p_z1_given_x + p_z2_given_x)) %>% \n",
    "    mutate(p_z2_given_x =  1 - p_z1_given_x )\n",
    "}  \n",
    "\n",
    "classifications <-classification_curve(data_1d, mybw) \n",
    "head(classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc38fcfc262b3f45d9e6fb45e62dee5b",
     "grade": false,
     "grade_id": "cell-eb25dc5d7d89c1c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can plot the classification curve. As you might expect, the exemplar model assigns very spiky and very smooth objects to category 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fc5fa6e0b700058373841511c3a48f9",
     "grade": false,
     "grade_id": "cell-0f20674aa6de9003",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "classification_plot_1d <- function(classifications, data) {\n",
    "  c_plot <-  classifications %>% \n",
    "    ggplot(aes(x = x, y = p_z1_given_x)) +\n",
    "    geom_line() +\n",
    "    geom_point(data = data, aes(x = x, y = 0, color = z, group = z)) +\n",
    "    labs(color='category (z)') +\n",
    "    ylab(\"p(z=1|x)\")\n",
    "}\n",
    "print(classification_plot_1d(classifications, data_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b534e701ad62a4805af2eb929fc8758",
     "grade": false,
     "grade_id": "cell-5d90722912275af6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's try another data set with category 1 observations at `{-0.6, -0.5, -0.4}` and category 2 observations at `{0.4, 0.41, 0.42}`. For both categories the point closest to 0 lies at a distance of 0.4 from `x=0`. The category 1 exemplars, however, are spaced more widely than are the category 2 exemplars. Again we'll plot the category densities ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34128cfe46b38e398a6af1f878466c5b",
     "grade": false,
     "grade_id": "cell-a5a1e0f71666399f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_1d_spacing <- tibble(x = c(-0.6, -0.5, -0.4, 0.4,0.41,0.42),\n",
    "                  z = factor( c(1,1,1,2,2,2) ))\n",
    "print(exemplar_plot_1d(data_1d_spacing, bw=mybw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca40a3e620f35d673411a0dc27fa8abf",
     "grade": false,
     "grade_id": "cell-04f8eab6aa4d5767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "... and the classification function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a25e1f319f57c8371deabf4396dddc43",
     "grade": false,
     "grade_id": "cell-1c68485dda6628ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "classifications_spacing <-classification_curve(data_1d_spacing, mybw) \n",
    "print(classification_plot_1d(classifications_spacing, data_1d_spacing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d701d99b8c941af22ba2031b803961da",
     "grade": false,
     "grade_id": "cell-59071feec012d5c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "The classification function for the 1D data set with variable spacing indicates that a new object at `x=0` is more likely to belong to category 2 than to category 1. Explain why the exemplar model makes this prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84fc410b5168a2d28ea4a1cf89496403",
     "grade": true,
     "grade_id": "cell-685a1acb9130f1ec",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38b0802d8b320b3d52c03f8b8b59af1f",
     "grade": false,
     "grade_id": "cell-8478f6eba81d21b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Prototype model\n",
    "\n",
    "Now let's build a prototype model using NIMBLE. We'll assume that category $i$ corresponds to a Gaussian distribution with mean `mu_i` and variance `s2_i`. We'll need to specify priors on these distributions, and the code below uses uniform priors. Let's start with the original data set `data_1d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0f1ad84438a1f614b298845b9925c3e",
     "grade": false,
     "grade_id": "cell-d7731b52cffd8fae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "code <- nimbleCode({\n",
    "  for(i in 1:M) {\n",
    "    mu[i] ~ dunif(-2,2)  # uniform prior on the interval [-2,2]\n",
    "    s2[i] ~ dunif(0,2)    # uniform prior on the interval [0,2]\n",
    "  }  \n",
    "  \n",
    "  pz2 ~ dunif(0,1)        # base rate of category 2 drawn from a uniform prior on the interval [0,1]\n",
    "  \n",
    "  for(i in 1:N) {\n",
    "    # z_ind is a vector of indicator variables (0 or 1)\n",
    "    # z_ind[i] is generated by flipping a weighted coin where the weight is pz2\n",
    "    z_ind[i] ~ dbern(pz2)       \n",
    "    # each data point x is drawn from a Gaussian distribution. We need to add 1 to z_ind to map the \n",
    "    # indicator variables (0 or 1) to categories 1 and 2\n",
    "    x[i] ~ dnorm(mu[z_ind[i]+1], var = s2[z_ind[i]+1])  \n",
    "  }  \n",
    "})\n",
    "\n",
    "constants <- list(\n",
    " M = 2,\n",
    " N = length(data_1d$x)\n",
    ")\n",
    "\n",
    "data <- list(\n",
    " x = data_1d$x,\n",
    " z_ind = as.numeric(data_1d$z) - 1\n",
    ")\n",
    "\n",
    "inits <- list(\n",
    " pz2 = 0.5,\n",
    " mu= c(0, 0),\n",
    " s2= c(1, 1)\n",
    ")\n",
    "\n",
    "samples <- nimbleMCMC(\n",
    "    code = code,\n",
    "    constants = constants,\n",
    "    data = data,\n",
    "    inits = inits,\n",
    "    monitors = c(\"mu\", \"s2\", \"pz2\"),\n",
    ")\n",
    "\n",
    "samples_1d <- as_tibble(samples) %>% \n",
    "  clean_names()\n",
    "\n",
    "head(samples_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f9fe4e6043cd09d3b39577bba59afe4",
     "grade": false,
     "grade_id": "cell-d906859b912c425a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have our samples let's take the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "347aab6a2ceee92580af20e8cf42fbd2",
     "grade": false,
     "grade_id": "cell-ed2a9d016d4c7ecc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "colMeans(samples_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9371206ce752f90b354e0a823ab481b3",
     "grade": false,
     "grade_id": "cell-3ea38b3332f39094",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Explain why the variance for category 1 (ie `s2_1`) is bigger than the variance for category 2 (`s2_2`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04fbbb6d6d1a705831fb8245f8efd423",
     "grade": true,
     "grade_id": "cell-655f8b705fbb1670",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "498ffdd3e0d03a1fba8713c24b91c289",
     "grade": false,
     "grade_id": "cell-17041846659c94b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can compute the likelihood $p(x|z)$ according to the prototype model by *summing out* (ie averaging over possible values of) the parameters `mu` and `s2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6770d7d5fa358677fc85c4b18ceccb1",
     "grade": false,
     "grade_id": "cell-b4d0986613b47173",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# First put samples_1d in long form.\n",
    "samples_1d_long <- samples_1d %>% \n",
    "   pivot_longer(c(\"mu_1\", \"mu_2\", \"s2_1\", \"s2_2\"), names_to = c(\".value\", \"z\"), names_sep=\"_\") %>% \n",
    "   mutate(z = as.numeric(z))\n",
    "\n",
    "# compute p(x=X|z=CATEGORY)  based on the samples in SAMPLES\n",
    "p_x_given_z_prot <- function(samples, category, x){\n",
    "  xval <- samples %>% \n",
    "    filter(z == category) %>% \n",
    "    mutate(x_given_z = dnorm(x, mean = mu, sd = sqrt(s2))) %>% \n",
    "    summarize(mean_x_given_z = mean(x_given_z)) %>% \n",
    "    pull()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41ee1b73e0761f810471a99e1a6216f5",
     "grade": false,
     "grade_id": "cell-17f5fed23c65cc97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll also use the samples to estimate $P(z=1)$ and $P(z=2)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07d25c62391bd5a870bd9fe9d6228248",
     "grade": false,
     "grade_id": "cell-9167dc85bcfdf4f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute p(z=CATEGORY)  based on the samples in SAMPLES\n",
    "p_z_prot <- function(samples, category){\n",
    "  pz <- samples %>% \n",
    "    mutate(pz1 = 1 - pz2) %>% \n",
    "    filter(z == category) %>% \n",
    "    mutate(pz = if_else(z == 1, pz1, pz2)) %>% \n",
    "    summarize(mean_pz = mean(pz)) %>% \n",
    "    pull()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb4922285c2855d53d19eac2d4b19774",
     "grade": false,
     "grade_id": "cell-c6d4e0a072eb0332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can multiply the prior and likelihood then renormalize to compute $p(z=1|x)$ over a grid of points between -3 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fc31956de07fbedf05c747527bba0d2",
     "grade": false,
     "grade_id": "cell-f0e3ccd3c33f43d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "classification_curve_prot <- function(samples) {\n",
    "  pz1 = p_z_prot(samples, 1)  \n",
    "  pz2 = p_z_prot(samples, 2)  \n",
    "  classifications <- tibble(x = seq(-3, 3, 0.01)) %>% \n",
    "    # compute p(z) for all x\n",
    "    mutate(p_z1 = pz1) %>% \n",
    "    mutate(p_z2 = pz2) %>% \n",
    "    # compute p(x|z) \n",
    "    mutate(p_x_given_z1 = map_dbl(x, ~p_x_given_z_prot(samples, 1, .))) %>% \n",
    "    mutate(p_x_given_z2 = map_dbl(x, ~p_x_given_z_prot(samples, 2, .))) %>% \n",
    "    # compute p(z|x) up to normalizing constant\n",
    "    mutate(p_z1_given_x = p_x_given_z1*p_z1) %>% \n",
    "    mutate(p_z2_given_x = p_x_given_z2*p_z2) %>% \n",
    "    # normalize p(z|x) \n",
    "    mutate(p_z1_given_x = p_z1_given_x /(p_z1_given_x + p_z2_given_x)) %>% \n",
    "    mutate(p_z2_given_x =  1 - p_z1_given_x )\n",
    "}  \n",
    "\n",
    "classifications <-classification_curve_prot(samples_1d_long) \n",
    "head(classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4b93399afb830811faba9caa57d382a",
     "grade": false,
     "grade_id": "cell-efe5d80d7a7c7ba5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot the categories inferred by the model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0950c4b4129837fa79f1cbdf391aade5",
     "grade": false,
     "grade_id": "cell-63c0227ff7f5dc47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "categorydensity_plot_1d <- function(classifications, data) {\n",
    "  c_plot <-  classifications %>% \n",
    "    pivot_longer(cols=c(\"p_x_given_z1\", \"p_x_given_z2\"), names_to = \"z\", values_to = \"p_x\") %>% \n",
    "    mutate(z = factor(recode(z, \"p_x_given_z1\"=1, \"p_x_given_z2\"=2))) %>% \n",
    "    ggplot(aes(x = x, y = p_x, color = z, group = z )) +\n",
    "    geom_line() +\n",
    "    geom_point(data = data, aes(x = x, y = 0, color = z, group = z)) +\n",
    "    labs(color='category (z)') +\n",
    "    ylab(\"density p(x|z)\")\n",
    "}\n",
    "\n",
    "print(categorydensity_plot_1d(classifications, data_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f9ee8d67ba2e749a18a412c0b8a0a2d",
     "grade": false,
     "grade_id": "cell-61ec4e359d71b1e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "and the classification function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de0168250f4a808b8db6fc964642a8bc",
     "grade": false,
     "grade_id": "cell-dcb701706e331e0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(classification_plot_1d(classifications, data_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d211d276b5458cfc231db1feaa90cf6",
     "grade": false,
     "grade_id": "cell-9fdce8656304115f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "The mean of category 1 is smaller than the mean of category 2. So why does the prototype model predict that objects with large values of x (greater than 1.65 or so) belong to category 1?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87c8b75abbd13f037768e6c48fb334fe",
     "grade": true,
     "grade_id": "cell-f836798a6bb1269b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcf5a9c6ea874fc74c72c46fdd63f15d",
     "grade": false,
     "grade_id": "cell-409b2eed9fcd91f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's now apply the prototype model to the data set with variable spacing. We'll need to run NIMBLE again to collect a bag of samples. The NIMBLE code stays the same as before but we need to adjust the `constants` and `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "988e129c272b3fd51375dfe1f7e042ed",
     "grade": false,
     "grade_id": "cell-a947b218ca96ee67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "constants <- list(\n",
    " M = 2,\n",
    " N = length(data_1d_spacing$x)\n",
    ")\n",
    "\n",
    "data <- list(\n",
    " x = data_1d_spacing$x,\n",
    " z_ind = as.numeric(data_1d_spacing$z) - 1\n",
    ")\n",
    "\n",
    "samples <- nimbleMCMC(\n",
    "    code = code,\n",
    "    constants = constants,\n",
    "    data = data,\n",
    "    inits = inits,\n",
    "    monitors = c(\"mu\", \"s2\", \"pz2\")\n",
    ")\n",
    "\n",
    "samples_1d_spacing_long <- as_tibble(samples) %>% \n",
    "  clean_names() %>% \n",
    "  pivot_longer(c(\"mu_1\", \"mu_2\", \"s2_1\", \"s2_2\"), names_to = c(\".value\", \"z\"), names_sep=\"_\") %>% \n",
    "   mutate(z = as.numeric(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1432584aa0d0fd685a84dce175a64b92",
     "grade": false,
     "grade_id": "cell-e0d006c44c449586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can use these samples to plot the category densities and classification function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22d8a8951cd9d868d46c7ce2f74150e0",
     "grade": false,
     "grade_id": "cell-bf1964d151f89f4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "classifications_spacing <-classification_curve_prot(samples_1d_spacing_long) \n",
    "print(categorydensity_plot_1d(classifications_spacing, data_1d_spacing))\n",
    "print(classification_plot_1d(classifications_spacing, data_1d_spacing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a9255d2f3d69f46255b821cbf4293c2",
     "grade": false,
     "grade_id": "cell-0aec12315488ccd1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "The prototype model model predicts that a new object at `x=0` is more likely to belong to category 1 than to category 2, which is different from what the exemplar model predicted. Why does the prototype model make the prediction that it does?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38e8aee5874a772c152d0740669956f7",
     "grade": true,
     "grade_id": "cell-0386a8e2e2c9026d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d2fe81e0440eeec9191db0388d26e7f",
     "grade": false,
     "grade_id": "cell-17d8593dd97b1c83",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "A behavioral experiment could be used to determine whether people's inferences about the variable spacing data set are more consistent with the prototype model or the exemplar model. Which model do you think would account better for people's judgments about a novel object at $x=0$?  Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8c9a48ed32878e2b5213131f74f0021",
     "grade": true,
     "grade_id": "cell-f9ab01b7f07c8c96",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c4f115ae81c00b81c7d7bed740261d4",
     "grade": false,
     "grade_id": "cell-1988cad9e027a977",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Behavioral experiments\n",
    "\n",
    "There is a large literature comparing the performance of models including exemplar and prototype models with human categorization. Experiment 2 of Fried and Holyoak (1984), [Induction of Category Distributions: A Framework for Classification Learning]( http://reasoninglab.psych.ucla.edu/KH%20pdfs/Fried_Holyoak.1984.pdf ) suggests that the prototype model may account better than the exemplar model for the variable spacing example.\n",
    "\n",
    "Across the entire experimental literature, however, the exemplar model generally tends to perform better than the prototype model as an account of human inferences.  One paper describing an experiment where the exemplar model performs very well is Nosofsky (1989), [Further tests of an exemplar similarity approach to relating identification and categorization](  https://link.springer.com/content/pdf/10.3758/BF03204942.pdf ), and you'll learn more about this experiment in the assessment for this week.\n",
    "\n",
    "## OPTIONAL: Two dimensional data sets\n",
    "\n",
    "We've focused on 1-dimensional data sets for ease of plotting, but both exemplar and prototype models can be applied to problems involving objects that vary along multiple dimensions. The assessment for this week will look at a 2-dimensional classification problem explored by Nosofsky (1989). Here we'll consider data collected by [Iain Murray]( https://homepages.inf.ed.ac.uk/imurray2/teaching/oranges_and_lemons/), who measured the height, width and mass of a set of oranges, lemons, and apples. We'll apply an exemplar model to the height and width data for oranges and lemons. The category density for oranges, say, is formed by dropping an axis-aligned Gaussian kernel on the data point for each orange then averaging all of these bumps to form the overall density for the category.\n",
    "\n",
    "Let's make a contour plot showing the densities for the two categories (oranges and lemons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9af3c4cc6f152c5d2410566a09265104",
     "grade": false,
     "grade_id": "cell-9de1b3a92c32c3d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_2d <- read_csv(\"oranges_lemons.csv\", show_col_types = FALSE) %>% \n",
    "    mutate(z = recode(z, `1`=\"orange\", `2`=\"lemon\")) %>% \n",
    "    mutate(z = factor(z, levels = c(\"orange\", \"lemon\")))\n",
    "\n",
    "exemplar_plot_2d <- function(data, h=NULL) {\n",
    "  e_plot <-  data %>% \n",
    "    ggplot(aes(x = width, y = height, color = z, group = z)) +\n",
    "    geom_density_2d(h = h) +\n",
    "    geom_point(aes(x=width, y=height)) +\n",
    "    theme(aspect.ratio=1)\n",
    "\n",
    "  return(e_plot)\n",
    "}\n",
    "\n",
    "print(exemplar_plot_2d(data_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bda8cab7172d96cd762861fb41203321",
     "grade": false,
     "grade_id": "cell-6800d8888ce2a229",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "The plot above uses the default value of the kernel bandwidth. You can set the bandwidth yourself using a call like\n",
    "`print(exemplar_plot_2d(data_2d, h = c(0.2, 0.2)))`. \n",
    "\n",
    "### Optional Exercise 6\n",
    "\n",
    "Try setting the bandwidth to `c(0.2,0.2)`, which specifies a Gaussian kernel with a standard deviation of 0.2 along each dimension.  Why does the plot now look as it does?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "467f3613158da501166aff3d46fdb72a",
     "grade": true,
     "grade_id": "cell-381a09fd61cf1781",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f579b4f009e84adefe1cf657ef918d8d",
     "grade": false,
     "grade_id": "cell-5900ffe0ef682d00",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Optional Exercise 7\n",
    "\n",
    "Imagine that the bandwidth is set to `c(0.1,0.25)`, which indicates that the variance of the Gaussian kernel is greater along the height dimension than the size dimension. What do you expect to see now when you plot the category densities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bd6e5c3b51e2856b0e1d1bebed8058f",
     "grade": true,
     "grade_id": "cell-fb9ac6e4c9c5b717",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
