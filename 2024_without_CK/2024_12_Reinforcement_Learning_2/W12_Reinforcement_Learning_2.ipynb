{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b74e53d20c495d12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# CBS Week 12 Assessment\n",
    "## Semester 2 2024\n",
    "\n",
    "\n",
    "This notebook is due on October 21st. Please make sure that your notebook validates before you submit it --- if your notebook doesn't validate the automated grader may run into issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f22f3ecf51ed178",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "    library(testthat)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd9f121d99c2711c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Bellman Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a905dad8997e25ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bellman = function(MDP, maxiters=10000, verbose=FALSE){\n",
    "        states <- MDP$states\n",
    "        actions <- MDP$actions\n",
    "        S <- length(states)\n",
    "        A <- length(actions)\n",
    "        transitions <- MDP$transitions\n",
    "        rewards <- MDP$rewards\n",
    "        discount <- MDP$discount\n",
    "    \n",
    "        V <- rep(0, S)\n",
    "        for(i in 0:maxiters){\n",
    "            if(verbose){message(i)}\n",
    "            oldV <- V\n",
    "            Q <- matrix(0, S, A)\n",
    "            for(s in states){\n",
    "                for(a in actions){\n",
    "                    Q[s, a] <- sum((transitions[, a, s]) * (rewards[, a, s] + discount*V))\n",
    "                }\n",
    "            }\n",
    "            V <- apply(Q, 1, max, na.rm=TRUE)\n",
    "            if(!any(abs(V-oldV) > 0.00001)){\n",
    "                break\n",
    "            }\n",
    "            if(i + 1 == maxiters){\n",
    "                message('WARNING: Values did not converge')\n",
    "            }\n",
    "        }\n",
    "        return(list(policy=apply(Q, 1, which.max), value=V))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c4bffdd54fe3ade",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1\n",
    "\n",
    "Sumak left me to start working as a postie. His route includes three neighborhoods: Anise, Basil and Cardamon. Every day, they leave the delivery center with mail for all three neighborhoods and have to pick up packages at two neighborhoods. Normally, one of those packages are marked fragile. Sumak is a contract-postie, so he has to pay for their own insurance in case a package breaks and if one does his premium goes up. Therefore, they prefer to pick up the fragile packages last to minimize time being responsible. \n",
    "\n",
    "Sumak already took this class and so he wants to use reinforcement learning to help him plan what his route should be. They think the state space should be grounded in where they have visited so far. So there are 7 possible states: {Anise, Basil, Cardamon, Ansise|Basil, Anise|Cardamom, Basil|Cardamom, Anise|Basil|Cardamon} reflecting where they've been plus a start state and a goal state. At each state, he can chose to stay where he is, to go to any other neighborhood or to go home (i.e., the goal), which gives us four actions: {Anise, Basil, Cardamon, Goal}. He's worked out the transition matrix below. Take a look.\n",
    "\n",
    "They've abbreviated the neighborhoods with their first initial in the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cd78180b16074d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "states = c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "actions = c(1, 2, 3, 4)\n",
    "\n",
    "transitions = array(0, c(9, 4, 9))\n",
    "\n",
    "# Start\n",
    "transitions[, 1, 1] = c(0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
    "transitions[, 2, 1] = c(0, 0, 1, 0, 0, 0, 0, 0, 0)\n",
    "transitions[, 3, 1] = c(0, 0, 0, 1, 0, 0, 0, 0, 0)\n",
    "# A\n",
    "transitions[, 1, 2] = c(0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
    "transitions[, 2, 2] = c(0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
    "transitions[, 3, 2] = c(0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
    "# B\n",
    "transitions[, 1, 3] = c(0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
    "transitions[, 2, 3] = c(0, 0, 1, 0, 0, 0, 0, 0, 0)\n",
    "transitions[, 3, 3] = c(0, 0, 0, 0, 0, 0, 1, 0, 0)\n",
    "# C\n",
    "transitions[, 1, 4] = c(0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
    "transitions[, 2, 4] = c(0, 0, 0, 0, 0, 0, 1, 0, 0)\n",
    "transitions[, 3, 4] = c(0, 0, 0, 1, 0, 0, 0, 0, 0)\n",
    "# AB\n",
    "transitions[, 1, 5] = c(0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
    "transitions[, 2, 5] = c(0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
    "transitions[, 3, 5] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "# AC\n",
    "transitions[, 1, 6] = c(0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
    "transitions[, 2, 6] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "transitions[, 3, 6] = c(0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
    "# BC\n",
    "transitions[, 1, 7] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "transitions[, 2, 7] = c(0, 0, 0, 0, 0, 0, 1, 0, 0)\n",
    "transitions[, 3, 7] = c(0, 0, 0, 0, 0, 0, 1, 0, 0)\n",
    "# ABC\n",
    "transitions[, 1, 8] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "transitions[, 2, 8] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "transitions[, 3, 8] = c(0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
    "# Goal\n",
    "transitions[9,4,] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e6caf49ef368acae",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Let's make sure you're following them.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>Exercise 1</h3>\n",
    "\n",
    "Answer the following questions:\n",
    "    \n",
    "- If Sumak is in state 5, where have they been?\n",
    "- If Sumak is in state 3 and goes to Anise, which state do they end up in?\n",
    "- If Sumak went to Cardamon then Basil, which state do they end in?\n",
    "- If Sumak went immediately from Anise to state 6, which action did he take?\n",
    "\n",
    "(2 Points)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "- Q1 \n",
    "- Q2 \n",
    "- Q3 \n",
    "- Q4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-811da3d345cfd590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Sumak also made us a `make_reward` function! He gets 1 reward for every package, he's carrying before he goes home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad50c25148756d0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "make_reward = function(cost){\n",
    "    \n",
    "    a = cost[1]\n",
    "    b = cost[2]\n",
    "    c = cost[3]\n",
    "\n",
    "    rewards = array(0, c(9, 4, 9))\n",
    "\n",
    "    # A\n",
    "    rewards[, 1, 2] = c(0, a, 0, 0, 0, 0, 0, 0, 0)\n",
    "    rewards[, 2, 2] = c(0, 0, 0, 0, a, 0, 0, 0, 0)\n",
    "    rewards[, 3, 2] = c(0, 0, 0, 0, 0, a, 0, 0, 0)\n",
    "    # B\n",
    "    rewards[, 1, 3] = c(0, 0, 0, 0, b, 0, 0, 0, 0)\n",
    "    rewards[, 2, 3] = c(0, 0, b, 0, 0, 0, 0, 0, 0)\n",
    "    rewards[, 3, 3] = c(0, 0, 0, 0, 0, 0, b, 0, 0)\n",
    "    # C\n",
    "    rewards[, 1, 4] = c(0, 0, 0, 0, 0, c, 0, 0, 0)\n",
    "    rewards[, 2, 4] = c(0, 0, 0, 0, 0, 0, c, 0, 0)\n",
    "    rewards[, 3, 4] = c(0, 0, 0, c, 0, 0, 0, 0, 0)\n",
    "    # AB\n",
    "    rewards[, 1, 5] = c(0, 0, 0, 0, a+b, 0, 0, 0, 0)\n",
    "    rewards[, 2, 5] = c(0, 0, 0, 0, a+b, 0, 0, 0, 0)\n",
    "    rewards[, 3, 5] = c(0, 0, 0, 0, 0, 0, 0, a+b, 0)\n",
    "    # AC\n",
    "    rewards[, 1, 6] = c(0, 0, 0, 0, 0, a+c, 0, 0, 0)\n",
    "    rewards[, 2, 6] = c(0, 0, 0, 0, 0, 0, 0, a+c, 0)\n",
    "    rewards[, 3, 6] = c(0, 0, 0, 0, 0, a+c, 0, 0, 0)\n",
    "    # BC\n",
    "    rewards[, 1, 7] = c(0, 0, 0, 0, 0, 0, 0, b+c, 0)\n",
    "    rewards[, 2, 7] = c(0, 0, 0, 0, 0, 0, b+c, 0, 0)\n",
    "    rewards[, 3, 7] = c(0, 0, 0, 0, 0, 0, b+c, 0, 0)\n",
    "    # ABC\n",
    "    rewards[, 1, 8] = c(0, 0, 0, 0, 0, 0, 0, a+b+c, 0)\n",
    "    rewards[, 2, 8] = c(0, 0, 0, 0, 0, 0, 0, a+b+c, 0)\n",
    "    rewards[, 3, 8] = c(0, 0, 0, 0, 0, 0, 0, a+b+c, 0)\n",
    "    # Goal\n",
    "    rewards[9, 4, ] = c(0, 1, 1, 1, 2, 2, 2, 3, 0)\n",
    "\n",
    "    return(rewards)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-80ad19317c9a4264",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "All we need to do is specify the cost (i.e., the negative reward) of carying a package that might break from Anise, Basil and Cardamon. Now how should we do that? :/\n",
    "\n",
    "Well we know that fragile packages should be more costly than regular packages. And there shouldn't be any cost if they don't pick up a package. So Sumak has made the implementation assumption that fragile packages should have cost -0.4 and regular packages should have -0.2.\n",
    "\n",
    "Now, because each day they get 2 locations to pick up packages from and one of the packages will be fragile, there are actually 6 possible assignments Sumak might get: \n",
    "\n",
    "1. A:fragile, B:package, C:nothing\n",
    "2. A:fragile, B:nothing, C:package\n",
    "3. A:nothing, B:fragile, C:package\n",
    "4. A:package, B:fragile, C:nothing\n",
    "5. A:package, B:nothing, C:fragile\n",
    "6. A:nothing, B:package, C:fragile\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>Exercise 2</h3>\n",
    "\n",
    "\n",
    "Make a MDP for the rest of the possible reward functions.\n",
    "    \n",
    "By convention, we'll label a MDP based on the initials of the neighborhood with the fragile package followed by the initial of the neighborhood with the regular package. For example, if the fragile package is in Anise and the regular package is in Basil, the MDP should be called MDP_AB as provided below.\n",
    "\n",
    "    \n",
    "Assume $\\gamma=0.9$.\n",
    "\n",
    "(2pts)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile = NA # YOUR CODE HERE\n",
    "package = NA # YOUR CODE HERE\n",
    "\n",
    "MDP_AB = list(states=states,\n",
    "           actions=actions,\n",
    "           transitions=transitions,\n",
    "           rewards=make_reward(c(fragile, package, 0)),\n",
    "           discount= NA) #YOUR CODE HERE\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-203967ff79bc1df7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have an MDP for every possible assignment that Sumak might get, we want know what the best policies are for each problem and which policy would be a good default route---i.e., have the maximium expected reward across all assignments.\n",
    "\n",
    "Sumak wrote us a function that gives us the reward of using a policy for a given assignment $R(\\pi, \\text{MDP})$. \n",
    "\n",
    "They are such a thoughtful ficitonal student!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74e0266bbd871ccb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "reward = function(policy, MDP){\n",
    "    rew = 0\n",
    "    state = 1\n",
    "    for(i in 1:10){\n",
    "        if(state == 9){\n",
    "            break\n",
    "        }\n",
    "        action = policy[state]\n",
    "        rew = rew + sum(MDP$rewards[, action, state])\n",
    "        state = which.max(MDP$transitions[, action, state])\n",
    "    }\n",
    "    rew\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-034666dfd6feff01",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\n",
    "We want a default policy, that gives us the highest reward regardless of assignment. Therefore, we want to take the expected reward over all possible assignments:\n",
    "\n",
    "$$ E_{\\text{MDP}}[ R(\\pi, \\text{MDP})] = \\sum_{\\text{MDP}} P(\\text{MDP}) R(\\pi, \\text{MDP})$$\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>Exercise 3</h3>\n",
    "\n",
    "Compelete the following code to calculate the expected reward over all possible assignments.\n",
    "    \n",
    "Sumak's best guess for `p_MDP` is provided below.\n",
    "\n",
    "(2pts)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       MDP_AB, MDP_AC, MDP_BC, MDP_BA, MDP_CA, MDP_CB\n",
    "p_mdp=c(1/3,    1/4,    1/12,   1/6,    1/12,   1/12)\n",
    "\n",
    "# Here are the assignment MDPs\n",
    "assignments=list(MDP_AB, MDP_AC, MDP_BC, MDP_BA, MDP_CA, MDP_CB)\n",
    "\n",
    "# Here are the labels for each assignment\n",
    "assigns=c('MDP_AB', 'MDP_AC', 'MDP_BC', 'MDP_BA', 'MDP_CA', 'MDP_CB')\n",
    "\n",
    "\n",
    "# For each assignment's best policy\n",
    "for(pi in 1:length(assignments)){ \n",
    "\n",
    "    # Find the optimal policy\n",
    "    pol = NA # YOUR CODE HERE\n",
    "\n",
    "    # Create a variable to store the expected reward\n",
    "    er = 0\n",
    "    # For each assignment\n",
    "    for(mdp in 1:length(assignments)){\n",
    "        \n",
    "        # Calculate the reward R(pi, MDP) \n",
    "        r = NA # YOUR CODE HERE\n",
    "\n",
    "        # Update the expected rewards E[R(pi, MDP)]\n",
    "        er = NA # YOUR CODE HERE\n",
    "    }\n",
    "    message(assigns[pi], '  ', er)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-110649f1cb3c8bd5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>Exercise 4</h3>\n",
    "\n",
    "Which policy is the best policy to use as a default?\n",
    "    \n",
    "(2pts)\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03ada437d715126a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2\n",
    "\n",
    "Sumak's super anxious so they've been watching what the woman who he will replace is doing. On Monday, she goes to Anise then Basil then Cardamon. On Tuesday, she goes to Basil then Cardamon then Anise. On Wednesday, she goes to Basil then Anise then Cardamon. \n",
    "\n",
    "Sumak is freaking out! He thinks his beliefs about which assignments he's likely to get are completely wrong. Given these observed actions, which location is more likely to have a fragile package?\n",
    "\n",
    "To do this, he'll need to update his beliefs about assignments.\n",
    "\n",
    "Sumak's being nice one last time. They wrote a noisy simulator likelihood function `likelihood` that takes as input:\n",
    "\n",
    "- a data point `dp`, a string (e.g., doing to Cardamon to Basil to Anise would be 'CBA')\n",
    "- a MDP that generates the data point\n",
    "- sims, number of simulations to run\n",
    "- noise, amount of action select noise\n",
    "\n",
    "and returns as output a log likelihood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84e621ceb0c87c1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "likelihood = function(dp, MDP, sims=1500, noise=0.01){\n",
    "    set.seed(10890)\n",
    "    p = bellman(MDP)$policy\n",
    "    D = c()\n",
    "    for(d in 1:sims){\n",
    "        data = c()\n",
    "        state = 1\n",
    "        for(i in 1:5){\n",
    "            if(state == 9){\n",
    "                break\n",
    "            }\n",
    "            if(runif(1) > noise){\n",
    "                action = p[state]\n",
    "                data = append(data, c('A','B','C','')[action])\n",
    "                state = which.max(transitions[, action, state])\n",
    "            } else {\n",
    "                action = sample(4, 1)\n",
    "                data = append(data, c('A','B','C','')[action])\n",
    "                state = which.max(transitions[, action, state])\n",
    "            }\n",
    "        }\n",
    "        D = append(D, paste0(data,collapse=''))\n",
    "    }\n",
    "\n",
    "    out = data.frame(D=D) %>%\n",
    "        group_by(D) %>%\n",
    "        summarise(N=n(), p =N/sims) %>%\n",
    "        filter(D==dp) %>% pull(p) %>% log()\n",
    "    ifelse(length(out) < 1, log(0.001), out)\n",
    "}\n",
    "\n",
    "\n",
    "likelihood('CBA', MDP_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9b96e8f7744afd28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>Exercise 5</h3>\n",
    "\n",
    "Which location is more likely to have a fragile package? Justify your answer using Sumak's updated beliefs.\n",
    "\n",
    "(2pts)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-27acdd9a5db25746",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
